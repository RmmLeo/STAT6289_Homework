{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import torch\n",
    "import numpy \n",
    "import transformers\n",
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification, Trainer,TextClassificationPipeline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, problem_type=\"multi_label_classification\")\n",
    "num_labels=5\n",
    "model = AutoModelForSequenceClassification.from_pretrained('C:\\RMM\\Medical4\\multilabelmodel', num_labels=num_labels).to('cuda')\n",
    "pipe=TextClassificationPipeline(model=model,tokenizer=tokenizer,device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_x = np.load(\"multilabeltest.npy\",allow_pickle=True)\n",
    "cor_reviews = [review[1] for review in cor_x]\n",
    "cor_labels = [review[0] for review in cor_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_top_k(k, pred_label_no_mask, values, returned_tokens):\n",
    "    \"\"\"\n",
    "    masked the k tokens that have the max shap values\n",
    "    :param k: specify the largest k value\n",
    "    :param values: shap values\n",
    "    :param returned_tokens: a list of tokens\n",
    "    :return: review, which is a str constructed from a list words\n",
    "    \"\"\"\n",
    "    shap_values_0, shap_values_1,shap_values_2,shap_values_3,shap_values_4 = zip(*values)\n",
    "    if pred_label_no_mask == 0:\n",
    "        values = shap_values_0\n",
    "    elif  pred_label_no_mask == 1:\n",
    "        values = shap_values_1\n",
    "    elif  pred_label_no_mask == 2:\n",
    "        values = shap_values_2  \n",
    "    elif  pred_label_no_mask == 3:\n",
    "        values = shap_values_3  \n",
    "    elif  pred_label_no_mask == 4:\n",
    "        values = shap_values_4\n",
    "    # print(values)\n",
    "    values = np.array(values)\n",
    "    # ids_top_k = np.argpartition(values, -k)[-k:]\n",
    "    ids_top_k = (-values).argsort()[:k]\n",
    "    for idx in ids_top_k:\n",
    "        # print(idx)\n",
    "        returned_tokens[idx] = \"[UNK] \"\n",
    "    masked_review = \"\".join(returned_tokens)\n",
    "    # print(masked_review)\n",
    "    return masked_review\n",
    "\n",
    "def predict_label(pipe, masked_review):\n",
    "    \"\"\"\n",
    "    predict the label for the masked_review\n",
    "    :param pipe: pipeline\n",
    "    :param masked_review: string\n",
    "    :return: 0 or 1, indicating the label\n",
    "    \"\"\"\n",
    "    prediction = pipe([masked_review])\n",
    "    labelstr=prediction[0]['label']\n",
    "    if labelstr == 'LABEL_0':\n",
    "        pred_label=0\n",
    "    elif labelstr == 'LABEL_1':\n",
    "        pred_label=1\n",
    "    elif labelstr == 'LABEL_2':\n",
    "        pred_label=2\n",
    "    elif labelstr== 'LABEL_3':\n",
    "        pred_label=3\n",
    "    elif labelstr == 'LABEL_4':\n",
    "        pred_label=4\n",
    "    return pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 0-th review\n",
      "process 1-th review\n",
      "process 2-th review\n",
      "process 3-th review\n",
      "process 4-th review\n",
      "process 5-th review\n",
      "process 6-th review\n",
      "process 7-th review\n",
      "process 8-th review\n",
      "process 9-th review\n",
      "process 10-th review\n",
      "process 11-th review\n",
      "process 12-th review\n",
      "process 13-th review\n",
      "process 14-th review\n",
      "process 15-th review\n",
      "process 16-th review\n",
      "process 17-th review\n",
      "process 18-th review\n",
      "process 19-th review\n",
      "process 20-th review\n",
      "process 21-th review\n",
      "process 22-th review\n",
      "process 23-th review\n",
      "process 24-th review\n",
      "process 25-th review\n",
      "process 26-th review\n",
      "process 27-th review\n",
      "process 28-th review\n",
      "process 29-th review\n",
      "process 30-th review\n",
      "process 31-th review\n",
      "process 32-th review\n",
      "process 33-th review\n",
      "process 34-th review\n",
      "process 35-th review\n",
      "process 36-th review\n",
      "process 37-th review\n",
      "process 38-th review\n",
      "process 39-th review\n",
      "process 40-th review\n",
      "process 41-th review\n",
      "process 42-th review\n",
      "process 43-th review\n",
      "process 44-th review\n",
      "process 45-th review\n",
      "process 46-th review\n",
      "process 47-th review\n",
      "process 48-th review\n",
      "process 49-th review\n",
      "process 50-th review\n",
      "process 51-th review\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 52-th review\n",
      "process 53-th review\n",
      "process 54-th review\n",
      "process 55-th review\n",
      "process 56-th review\n",
      "process 57-th review\n",
      "process 58-th review\n",
      "process 59-th review\n",
      "process 60-th review\n",
      "process 61-th review\n",
      "process 62-th review\n",
      "process 63-th review\n",
      "process 64-th review\n",
      "process 65-th review\n",
      "process 66-th review\n",
      "process 67-th review\n",
      "process 68-th review\n",
      "process 69-th review\n",
      "process 70-th review\n",
      "process 71-th review\n",
      "process 72-th review\n",
      "process 73-th review\n",
      "process 74-th review\n",
      "process 75-th review\n",
      "process 76-th review\n",
      "process 77-th review\n",
      "process 78-th review\n",
      "process 79-th review\n",
      "process 80-th review\n",
      "process 81-th review\n",
      "process 82-th review\n",
      "process 83-th review\n",
      "process 84-th review\n",
      "process 85-th review\n",
      "process 86-th review\n",
      "process 87-th review\n",
      "process 88-th review\n",
      "process 89-th review\n",
      "process 90-th review\n",
      "process 91-th review\n",
      "process 92-th review\n",
      "process 93-th review\n",
      "process 94-th review\n",
      "process 95-th review\n",
      "process 96-th review\n",
      "process 97-th review\n",
      "process 98-th review\n",
      "process 99-th review\n",
      "process 100-th review\n",
      "process 101-th review\n",
      "process 102-th review\n",
      "process 103-th review\n",
      "process 104-th review\n",
      "process 105-th review\n",
      "process 106-th review\n",
      "process 107-th review\n",
      "process 108-th review\n",
      "process 109-th review\n",
      "process 110-th review\n",
      "process 111-th review\n",
      "process 112-th review\n",
      "process 113-th review\n",
      "process 114-th review\n",
      "process 115-th review\n",
      "process 116-th review\n",
      "process 117-th review\n",
      "process 118-th review\n",
      "process 119-th review\n",
      "process 120-th review\n",
      "process 121-th review\n",
      "process 122-th review\n",
      "process 123-th review\n",
      "process 124-th review\n",
      "process 125-th review\n",
      "process 126-th review\n",
      "process 127-th review\n",
      "process 128-th review\n",
      "process 129-th review\n",
      "process 130-th review\n",
      "process 131-th review\n",
      "process 132-th review\n",
      "process 133-th review\n",
      "process 134-th review\n",
      "process 135-th review\n",
      "process 136-th review\n",
      "process 137-th review\n",
      "process 138-th review\n",
      "process 139-th review\n",
      "process 140-th review\n",
      "process 141-th review\n",
      "process 142-th review\n",
      "process 143-th review\n",
      "process 144-th review\n",
      "process 145-th review\n",
      "process 146-th review\n",
      "process 147-th review\n",
      "process 148-th review\n",
      "process 149-th review\n",
      "process 150-th review\n",
      "process 151-th review\n",
      "process 152-th review\n",
      "process 153-th review\n",
      "process 154-th review\n",
      "process 155-th review\n",
      "process 156-th review\n",
      "process 157-th review\n",
      "process 158-th review\n",
      "process 159-th review\n",
      "process 160-th review\n",
      "process 161-th review\n",
      "process 162-th review\n",
      "process 163-th review\n",
      "process 164-th review\n",
      "process 165-th review\n",
      "process 166-th review\n",
      "process 167-th review\n",
      "process 168-th review\n",
      "process 169-th review\n",
      "process 170-th review\n",
      "process 171-th review\n",
      "process 172-th review\n",
      "process 173-th review\n",
      "process 174-th review\n",
      "process 175-th review\n",
      "process 176-th review\n",
      "process 177-th review\n",
      "process 178-th review\n",
      "process 179-th review\n",
      "process 180-th review\n",
      "process 181-th review\n",
      "process 182-th review\n",
      "process 183-th review\n",
      "process 184-th review\n",
      "process 185-th review\n",
      "process 186-th review\n",
      "process 187-th review\n",
      "process 188-th review\n",
      "process 189-th review\n",
      "process 190-th review\n",
      "process 191-th review\n",
      "process 192-th review\n",
      "process 193-th review\n",
      "process 194-th review\n",
      "process 195-th review\n",
      "process 196-th review\n",
      "process 197-th review\n",
      "process 198-th review\n",
      "process 199-th review\n",
      "process 200-th review\n",
      "process 201-th review\n",
      "process 202-th review\n",
      "process 203-th review\n",
      "process 204-th review\n",
      "process 205-th review\n",
      "process 206-th review\n",
      "process 207-th review\n",
      "process 208-th review\n",
      "process 209-th review\n",
      "process 210-th review\n",
      "process 211-th review\n",
      "process 212-th review\n",
      "process 213-th review\n",
      "process 214-th review\n",
      "process 215-th review\n",
      "process 216-th review\n",
      "process 217-th review\n",
      "process 218-th review\n",
      "process 219-th review\n",
      "process 220-th review\n",
      "process 221-th review\n",
      "process 222-th review\n",
      "process 223-th review\n",
      "process 224-th review\n",
      "process 225-th review\n",
      "process 226-th review\n",
      "process 227-th review\n",
      "process 228-th review\n",
      "process 229-th review\n",
      "process 230-th review\n",
      "process 231-th review\n",
      "process 232-th review\n",
      "process 233-th review\n",
      "process 234-th review\n",
      "process 235-th review\n",
      "process 236-th review\n",
      "process 237-th review\n",
      "process 238-th review\n",
      "process 239-th review\n",
      "process 240-th review\n",
      "process 241-th review\n",
      "process 242-th review\n",
      "process 243-th review\n",
      "process 244-th review\n",
      "process 245-th review\n",
      "process 246-th review\n",
      "process 247-th review\n",
      "process 248-th review\n",
      "process 249-th review\n",
      "process 250-th review\n",
      "process 251-th review\n",
      "process 252-th review\n",
      "process 253-th review\n",
      "process 254-th review\n",
      "process 255-th review\n",
      "process 256-th review\n",
      "process 257-th review\n",
      "process 258-th review\n",
      "process 259-th review\n",
      "process 260-th review\n",
      "process 261-th review\n",
      "process 262-th review\n",
      "process 263-th review\n",
      "process 264-th review\n",
      "process 265-th review\n",
      "process 266-th review\n",
      "process 267-th review\n",
      "process 268-th review\n",
      "process 269-th review\n",
      "process 270-th review\n",
      "process 271-th review\n",
      "process 272-th review\n",
      "process 273-th review\n",
      "process 274-th review\n",
      "process 275-th review\n",
      "process 276-th review\n",
      "process 277-th review\n",
      "process 278-th review\n",
      "process 279-th review\n",
      "process 280-th review\n",
      "process 281-th review\n",
      "process 282-th review\n",
      "process 283-th review\n",
      "process 284-th review\n",
      "process 285-th review\n",
      "process 286-th review\n",
      "process 287-th review\n",
      "process 288-th review\n"
     ]
    }
   ],
   "source": [
    "shap_values_list = []\n",
    "token_data_list = []\n",
    "top_k = [1, 5, 9, 13,17,21,25,29,33,37,31]\n",
    "all_labels =[]\n",
    "# use GPU\n",
    "gpu_explainer = shap.Explainer(pipe, tokenizer)\n",
    "i = 0\n",
    "for review, label in zip(cor_reviews, cor_labels):\n",
    "    label=label-1\n",
    "    print(f\"process {i}-th review\")\n",
    "    i += 1\n",
    "    label4review =[]\n",
    "    label4review.append(label)\n",
    "    # to-do: truncate review if len(review)>80\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    if len(tokens) > 80:\n",
    "        tokens_truncated = tokens[:80]\n",
    "        review = \" \".join(token for token in tokens_truncated)\n",
    "    pred_label_no_mask = predict_label(pipe, review) # predicted label for review without mask\n",
    "    label4review.append(pred_label_no_mask)\n",
    "    shap_values = gpu_explainer([review])\n",
    "    values = shap_values.values[0] # 2-dim ndarray\n",
    "    returned_tokens = shap_values.data[0]\n",
    "    for k in top_k:\n",
    "        masked_review = mask_top_k(k, pred_label_no_mask, values, returned_tokens) # mask review by the shap values\n",
    "        predicted_label= predict_label(pipe, masked_review)\n",
    "        label4review.append(predicted_label)\n",
    "    # label4review = [True_label, pred_label_without_mask, masked_label_1, masked_label_2, masked_review_3, masked_review_4]\n",
    "    all_labels.append(label4review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df.loc[df[0]==df[1]]\n",
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7857142857142857 0.5642857142857143 0.5071428571428571 0.4928571428571429 0.4857142857142857 0.4714285714285714 0.45 0.45 0.45 0.45714285714285713 0.45714285714285713\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(filtered_df[1], filtered_df[2]), accuracy_score(filtered_df[1], filtered_df[3]), accuracy_score(filtered_df[1], filtered_df[4]), accuracy_score(filtered_df[1], filtered_df[5]),accuracy_score(filtered_df[1], filtered_df[6]),accuracy_score(filtered_df[1], filtered_df[7]),accuracy_score(filtered_df[1], filtered_df[8]),accuracy_score(filtered_df[1], filtered_df[9]),accuracy_score(filtered_df[1], filtered_df[10]),accuracy_score(filtered_df[1], filtered_df[11]),accuracy_score(filtered_df[1], filtered_df[12]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4aa083d928abac1bb4c2de21863d23e101a74b57ce6d7b6a3a0a67f44f67e603"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('Leo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
